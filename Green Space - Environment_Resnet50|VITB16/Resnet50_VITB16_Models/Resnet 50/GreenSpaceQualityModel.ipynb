{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4085198-7a09-4fcb-bcea-ac75baa6e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "× ××¦××• 987 ×§×‘×¦×™×.\n",
      "  Healthy: 334\n",
      "  Dried: 322\n",
      "  Contaminated: 331\n",
      "Train: 690 | Val: 98 | Test: 199\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5fb813dc3d4b2aa92df2b7dfe16424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b16e8fd2824428e96820596cd60c433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.8316 | Train Acc: 0.6971\n",
      "  Val   Loss: 1.1527 | Val   Acc: 0.6122\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98abaac4811f4ba38e2433db072ea274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f9993330d7414d9f18c2b0a306d552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.4099 | Train Acc: 0.8696\n",
      "  Val   Loss: 4.9473 | Val   Acc: 0.6633\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68d6cb383a244b89a0179a4d3332827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5084d055324410db345e966aad60f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.2951 | Train Acc: 0.9014\n",
      "  Val   Loss: 0.5725 | Val   Acc: 0.7857\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520879a396644433b137287265804dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638f8ec5d40e4d16b7a91842b13f5a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.1984 | Train Acc: 0.9348\n",
      "  Val   Loss: 0.9454 | Val   Acc: 0.7143\n",
      "  No improvement for 1 epoch(s).\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aa7756699244b49ecb721eaaa0c643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67155df63a8c430da66c21a153e828f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.2302 | Train Acc: 0.9116\n",
      "  Val   Loss: 0.4515 | Val   Acc: 0.8367\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cfcbeefab745ab9ebc5682ebdbe590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320fe390ee4943aabb95271377438053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.2480 | Train Acc: 0.9130\n",
      "  Val   Loss: 0.3403 | Val   Acc: 0.8673\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3617198390e34f48a4bfb31bf57ee1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f18455a5b354564a1fa9ad8896c62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.2220 | Train Acc: 0.9203\n",
      "  Val   Loss: 0.3663 | Val   Acc: 0.8673\n",
      "  No improvement for 1 epoch(s).\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f16e757c34a4d97a8e85319a786f0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a2414b0e7245b1acef05a88ea4e065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.1524 | Train Acc: 0.9522\n",
      "  Val   Loss: 0.1850 | Val   Acc: 0.9388\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7552fd625574b59bc88acb43856de24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ac65fc07f34563abc2f51f2adcc4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.1647 | Train Acc: 0.9464\n",
      "  Val   Loss: 0.1704 | Val   Acc: 0.9388\n",
      "  No improvement for 1 epoch(s).\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e0d43f31794543a3a357f05338efb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c557647422e4ab9aada1ae97470e995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.1546 | Train Acc: 0.9551\n",
      "  Val   Loss: 0.2459 | Val   Acc: 0.9082\n",
      "  No improvement for 2 epoch(s).\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb819e08bd04a25a0ecc3d0d5fcecdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316b21ef8ede4e92a646a256ca08f2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.1341 | Train Acc: 0.9652\n",
      "  Val   Loss: 0.3243 | Val   Acc: 0.8980\n",
      "  No improvement for 3 epoch(s).\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85186292de348bf9a0e2573dc3c625c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0616bf786a75450194c7986a1587b738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.1237 | Train Acc: 0.9565\n",
      "  Val   Loss: 0.0782 | Val   Acc: 0.9796\n",
      "  >>> Improvement, saving best model in memory.\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205d27f80215401dbfa548f05593cfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501c01fcb77f496b98c96f6b3f9454e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.0722 | Train Acc: 0.9725\n",
      "  Val   Loss: 0.0652 | Val   Acc: 0.9796\n",
      "  No improvement for 1 epoch(s).\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafd4d3084774f9591262fd0a26c5a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287fb95a91c442bbb640be3aac3e8b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.0435 | Train Acc: 0.9884\n",
      "  Val   Loss: 0.0584 | Val   Acc: 0.9796\n",
      "  No improvement for 2 epoch(s).\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a421d23aa5614d23b354cf84641c769d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39261b8f857d4695a31dfc4b7c0b1d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.0247 | Train Acc: 0.9971\n",
      "  Val   Loss: 0.0486 | Val   Acc: 0.9796\n",
      "  No improvement for 3 epoch(s).\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce974f9127f4d84ba047d9f1b3fee5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50262d9b102b462c81029a19fa8605fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.0390 | Train Acc: 0.9899\n",
      "  Val   Loss: 0.0419 | Val   Acc: 0.9796\n",
      "  No improvement for 4 epoch(s).\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadd9b02dd9e468fbaf56b4625877dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d36ae3339944674b89252bc45300856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.0430 | Train Acc: 0.9870\n",
      "  Val   Loss: 0.0428 | Val   Acc: 0.9796\n",
      "  No improvement for 5 epoch(s).\n",
      "Early stopping (patience=5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4807f34723944c2a313764012b61852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Test Set ===\n",
      "Test Loss: 0.0326 | Test Acc: 0.9899\n",
      "\n",
      "Metrics (summary):\n",
      "accuracy: 0.9899\n",
      "precision_macro: 0.9900\n",
      "recall_macro: 0.9900\n",
      "f1_macro: 0.9900\n",
      "kappa: 0.9849\n",
      "roc_auc_macro_ovr: 0.9997\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Healthy     0.9851    0.9851    0.9851        67\n",
      "       Dried     1.0000    1.0000    1.0000        65\n",
      "Contaminated     0.9851    0.9851    0.9851        67\n",
      "\n",
      "    accuracy                         0.9899       199\n",
      "   macro avg     0.9900    0.9900    0.9900       199\n",
      "weighted avg     0.9899    0.9899    0.9899       199\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[66  0  1]\n",
      " [ 0 65  0]\n",
      " [ 1  0 66]]\n",
      "\n",
      "Saved model to: outputs_gsq_torch\\model_resnet50.pt\n",
      "Saved metrics to: outputs_gsq_torch\\test_metrics.json\n",
      "Saved training history to: outputs_gsq_torch\\history.json\n",
      "\n",
      "Creating Grad-CAM overlays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\greenspace\\lib\\site-packages\\torch\\nn\\modules\\module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: outputs_gsq_torch\\gradcam\\class0_img-healthy (8).png\n",
      "  Saved: outputs_gsq_torch\\gradcam\\class0_img-healthy (726)-aug.png\n",
      "  Saved: outputs_gsq_torch\\gradcam\\class1_img-dried (1).png\n",
      "  Saved: outputs_gsq_torch\\gradcam\\class1_img-dried (795).png\n",
      "  Saved: outputs_gsq_torch\\gradcam\\class2_img-cont (728).png\n",
      "  Saved: outputs_gsq_torch\\gradcam\\class2_img-cont (587).png\n",
      "\n",
      "Saved split config to: outputs_gsq_torch\\split_config.json\n",
      "\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Green Space Quality â€“ PyTorch Training Pipeline\n",
    "===============================================\n",
    "×©×—×–×•×¨ ×”× ×™×¡×•×™ ×©×œ ×”××××¨ \"Green Space Quality Analysis Using Machine Learning Approaches\"\n",
    "××‘×œ ×¢× PyTorch + CUDA ×‘××§×•× TensorFlow, ×ª×•×š ×©××™×¨×” ×¢×œ:\n",
    "- ×—×œ×•×§×” 70/10/20 (××™××•×Ÿ/×•×œ×™×“×¦×™×”/×‘×“×™×§×”) â€“ ×¡×˜×¨×˜×™×¤×™×ª\n",
    "- ResNet50 Pretrained (ImageNet)\n",
    "- ××•×’×× ×˜×¦×™×•×ª ×“×•××•×ª (Albumentations)\n",
    "- ××“×“×™×: Accuracy, Precision/Recall/F1 Macro, Cohen's Kappa, ROC-AUC (×××§×¨×• OVR)\n",
    "- Grad-CAM ×œ×“×•×’×××•×ª ××›×œ ××—×œ×§×”\n",
    "\n",
    "×œ×”×¨×¦×” (×‘-CMD/PowerShell, ××ª×•×š ×”×¡×‘×™×‘×” greenspace):\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# ğŸ”¹ HERE: Define configuration as variables (no argparse needed)\n",
    "# -----------------------------\n",
    "\n",
    "class Config:\n",
    "    root_dir = r\"C:\\afeca academy\\year 2\\CVDLP\\GreenSpaceQualityProject\\OriginalPictures\"\n",
    "    arch = \"resnet50\"\n",
    "    batch = 32\n",
    "    epochs = 50\n",
    "    seed = 42\n",
    "    save_dir = \"outputs_gsq_torch\"\n",
    "    patience = 5\n",
    "    gradcam_per_class = 2\n",
    "\n",
    "# Create args-like object\n",
    "args = Config()\n",
    "\n",
    "# ğŸ”¹ Classes (ensure they match your folder names)\n",
    "CLASS_NAMES = [\"Healthy\", \"Dried\", \"Contaminated\"]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "DEFAULT_SAVE_DIR = args.save_dir\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset ×•-Augs\n",
    "# -----------------------------\n",
    "\n",
    "def build_train_transform(img_size=224):\n",
    "    \"\"\"××•×’×× ×˜×¦×™×” ×‘×¡×’× ×•×Ÿ ×”××××¨.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.CLAHE(p=0.5),\n",
    "        A.Resize(img_size, img_size)\n",
    "    ])\n",
    "\n",
    "\n",
    "def build_eval_transform(img_size=224):\n",
    "    \"\"\"×˜×¨× ×¡×¤×•×¨××¦×™×” ×œ-Val/Test â€“ ×¨×§ resize (××¤×©×¨ ×’× normalize).\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size)\n",
    "    ])\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class GreenSpaceDataset(Dataset):\n",
    "    def __init__(self, files: List[str], labels: List[int],\n",
    "                 transform=None):\n",
    "        self.files = list(files)\n",
    "        self.labels = list(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Cannot read image: {path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented[\"image\"]\n",
    "\n",
    "        # albumentations ××—×–×™×¨ np.uint8 HWC, × ×¢×©×” × ×¨××•×œ ×œ-0..1 ×•××– normalize ×©×œ ImageNet\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = (img - IMAGENET_MEAN) / IMAGENET_STD\n",
    "        # HWC -> CHW\n",
    "        img = np.transpose(img, (0, 1, 2)) if img.ndim == 3 else img\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        img_tensor = torch.from_numpy(img).float()  # float32\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "\n",
    "def make_filelist(root_dir: Path, class_names: List[str]) -> Tuple[List[str], List[int]]:\n",
    "    files = []\n",
    "    labels = []\n",
    "    for idx, cname in enumerate(class_names):\n",
    "        cdir = root_dir / cname\n",
    "        if not cdir.exists():\n",
    "            raise FileNotFoundError(f\"Missing class folder: {cdir}\")\n",
    "        exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\", \"*.webp\")\n",
    "        for e in exts:\n",
    "            for p in cdir.glob(e):\n",
    "                files.append(str(p))\n",
    "                labels.append(idx)\n",
    "    return files, labels\n",
    "\n",
    "\n",
    "def stratified_split(files: List[str], labels: List[int], seed=42):\n",
    "    \"\"\"\n",
    "    ×—×œ×•×§×” 70/10/20 â€“ ××™××•×Ÿ/×•×œ×™×“×¦×™×”/×‘×“×™×§×” â€“ ×¢× ×©××™×¨×” ×¢×œ ×™×—×¡ ××—×œ×§×•×ª (stratified).\n",
    "    \"\"\"\n",
    "    files = np.array(files)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Train 70%, Temp 30%\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=seed)\n",
    "    train_idx, temp_idx = next(sss1.split(files, labels))\n",
    "    X_train, y_train = files[train_idx], labels[train_idx]\n",
    "    X_temp, y_temp = files[temp_idx], labels[temp_idx]\n",
    "\n",
    "    # ××ª×•×š Temp â€“ 1/3 Val, 2/3 Test -> 10%/20% ××”×›×œ\n",
    "    val_size = 1.0 / 3.0\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=(1.0 - val_size), random_state=seed)\n",
    "    val_idx, test_idx = next(sss2.split(X_temp, y_temp))\n",
    "    X_val, y_val = X_temp[val_idx], y_temp[val_idx]\n",
    "    X_test, y_test = X_temp[test_idx], y_temp[test_idx]\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ×‘× ×™×™×ª ×”××•×“×œ (ResNet50)\n",
    "# -----------------------------\n",
    "\n",
    "def build_model(arch: str = \"resnet50\", num_classes: int = NUM_CLASSES, pretrained: bool = True) -> nn.Module:\n",
    "    arch = arch.lower()\n",
    "    if arch == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported arch: {arch}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training / Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
    "\n",
    "    for xb, yb in pbar:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_labels.append(yb.detach().cpu().numpy())\n",
    "\n",
    "        # ×¢×“×›×•×Ÿ ×˜×§×¡×˜ ×§×˜×Ÿ ×¢×œ ×”Ö¾bar\n",
    "        current_loss = running_loss / max(1, len(all_labels) * loader.batch_size)\n",
    "        pbar.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, acc\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, device, criterion, desc=\"Eval\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=desc, leave=False)\n",
    "\n",
    "    for xb, yb in pbar:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(yb.cpu().numpy())\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "        current_loss = running_loss / max(1, len(all_labels) * loader.batch_size)\n",
    "        pbar.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, acc, all_labels, all_preds, all_probs\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(y_true_idx, y_pred_idx, y_proba, class_names):\n",
    "    # one-hot ×œ-ROC-AUC\n",
    "    num_classes = len(class_names)\n",
    "    y_true_oh = np.eye(num_classes)[y_true_idx]\n",
    "\n",
    "    acc = accuracy_score(y_true_idx, y_pred_idx)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true_idx, y_pred_idx, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    kappa = cohen_kappa_score(y_true_idx, y_pred_idx)\n",
    "\n",
    "    try:\n",
    "        rocauc = roc_auc_score(y_true_oh, y_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "    except Exception:\n",
    "        rocauc = float(\"nan\")\n",
    "\n",
    "    report = classification_report(y_true_idx, y_pred_idx, target_names=class_names, digits=4, zero_division=0)\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_macro\": prec,\n",
    "        \"recall_macro\": rec,\n",
    "        \"f1_macro\": f1,\n",
    "        \"kappa\": kappa,\n",
    "        \"roc_auc_macro_ovr\": rocauc,\n",
    "        \"report\": report,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Grad-CAM ×¤×©×•×˜ ×œ-ResNet50\n",
    "# -----------------------------\n",
    "\n",
    "def gradcam_resnet50(model, img_tensor, target_class, device, last_layer_name=\"layer4\"):\n",
    "    \"\"\"\n",
    "    img_tensor: tensor ×‘×¦×•×¨×ª (1,C,H,W) ×¢×œ device\n",
    "    target_class: ××™× ×“×§×¡ ××—×œ×§×”\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features = None\n",
    "    gradients = None\n",
    "\n",
    "    def fwd_hook(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output\n",
    "\n",
    "    def bwd_hook(module, grad_in, grad_out):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_out[0]\n",
    "\n",
    "    # ×”×©×›×‘×” ×”××—×¨×•× ×” ×”×™× model.layer4\n",
    "    last_layer = dict(model.named_modules())[last_layer_name]\n",
    "    handle_fwd = last_layer.register_forward_hook(fwd_hook)\n",
    "    handle_bwd = last_layer.register_backward_hook(bwd_hook)\n",
    "\n",
    "    # ×œ×•×•×“× float32 ×¢×œ ×”Ö¾device\n",
    "    img_tensor = img_tensor.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    logits = model(img_tensor)\n",
    "    score = logits[0, target_class]\n",
    "    model.zero_grad()\n",
    "    score.backward()\n",
    "\n",
    "    # gradients: (B, C, H, W)\n",
    "    grads = gradients[0]          # (C,H,W)\n",
    "    fmap = features[0]            # (C,H,W)\n",
    "\n",
    "    weights = torch.mean(grads, dim=(1, 2))  # (C,)\n",
    "    cam = torch.zeros(fmap.shape[1:], dtype=torch.float32, device=device)  # (H,W)\n",
    "    for w, f in zip(weights, fmap):\n",
    "        cam += w * f\n",
    "\n",
    "    cam = torch.relu(cam)\n",
    "    cam = cam - cam.min()\n",
    "    cam = cam / (cam.max() + 1e-8)\n",
    "    cam = cam.detach().cpu().numpy()\n",
    "\n",
    "    handle_fwd.remove()\n",
    "    handle_bwd.remove()\n",
    "    return cam  # HxW, ×‘×˜×•×•×— [0,1]\n",
    "\n",
    "\n",
    "\n",
    "def save_gradcam_overlay(orig_img_path, cam, out_path, img_size=224):\n",
    "    \"\"\"cam ×‘×’×•×“×œ HxW, orig_img_path â€“ ×ª××•× ×” ××§×•×¨×™×ª, × ×©××•×¨ overlay.\"\"\"\n",
    "    img = cv2.imread(orig_img_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        return\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "    heatmap = cv2.resize(cam, (img_size, img_size))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    overlay = cv2.addWeighted((img).astype(np.uint8), 0.6, heatmap, 0.4, 0)\n",
    "    overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(out_path, overlay)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# main\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # ××©×ª××©×™× ×‘-args ×©××’×™×¢ ×-Config ×‘×ª×—×™×œ×ª ×”×§×•×‘×¥\n",
    "    global args\n",
    "\n",
    "    # reproducibility\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    root = Path(args.root_dir)\n",
    "    assert root.exists(), f\"Root dir not found: {root}\"\n",
    "\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    # 1) ××™×¡×•×£ ×§×‘×¦×™×\n",
    "    files, labels = make_filelist(root, CLASS_NAMES)\n",
    "    print(f\"× ××¦××• {len(files)} ×§×‘×¦×™×.\")\n",
    "    uniq, counts = np.unique(labels, return_counts=True)\n",
    "    for i, c in zip(uniq, counts):\n",
    "        print(f\"  {CLASS_NAMES[i]}: {c}\")\n",
    "\n",
    "    # 2) ×—×œ×•×§×” 70/10/20\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = stratified_split(files, labels, seed=args.seed)\n",
    "    print(f\"Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "    # 3) DataLoaders â€“ num_workers=0 ×›×“×™ ×œ× ×œ×”×™×ª×§×¢ ×‘-Notebook ×¢×œ Windows\n",
    "    train_tf = build_train_transform(IMG_SIZE)\n",
    "    eval_tf = build_eval_transform(IMG_SIZE)\n",
    "\n",
    "    train_ds = GreenSpaceDataset(X_train, y_train, transform=train_tf)\n",
    "    val_ds = GreenSpaceDataset(X_val, y_val, transform=eval_tf)\n",
    "    test_ds = GreenSpaceDataset(X_test, y_test, transform=eval_tf)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch, shuffle=True,\n",
    "                              num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=args.batch, shuffle=False,\n",
    "                            num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=args.batch, shuffle=False,\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "    # 4) ××•×“×œ + Optimizer + Scheduler\n",
    "    model = build_model(args.arch, NUM_CLASSES, pretrained=True)\n",
    "    model = model.to(device).float()   # ×œ×•×•×“× float32 ×¢×œ ×”-GPU/CPU\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", factor=0.1, patience=2\n",
    "    )\n",
    "\n",
    "    # 5) ×œ×•×œ××ª ××™××•×Ÿ ×¢× Early Stopping ×¢×œ val_accuracy\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{args.epochs}\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device, criterion)\n",
    "        val_loss, val_acc, _, _, _ = eval_epoch(model, val_loader, device, criterion, desc=\"Val\")\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc + 1e-4:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "            print(\"  >>> Improvement, saving best model in memory.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= args.patience:\n",
    "            print(f\"Early stopping (patience={args.patience})\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # 6) ×”×¢×¨×›×” ×¢×œ Test + ××“×“×™×\n",
    "    test_loss, test_acc, y_true, y_pred, y_proba = eval_epoch(\n",
    "        model, test_loader, device, criterion, desc=\"Test\"\n",
    "    )\n",
    "    print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    metrics = compute_metrics(y_true, y_pred, y_proba, CLASS_NAMES)\n",
    "    print(\"\\nMetrics (summary):\")\n",
    "    for k in [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"kappa\", \"roc_auc_macro_ovr\"]:\n",
    "        v = metrics[k]\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\", metrics[\"report\"])\n",
    "    print(\"\\nConfusion Matrix:\\n\", np.array(metrics[\"confusion_matrix\"]))\n",
    "\n",
    "    # 7) ×©××™×¨×ª ××•×“×œ ×•××“×“×™×\n",
    "    model_path = os.path.join(args.save_dir, f\"model_{args.arch}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"\\nSaved model to: {model_path}\")\n",
    "\n",
    "    out_metrics_path = os.path.join(args.save_dir, \"test_metrics.json\")\n",
    "    with open(out_metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved metrics to: {out_metrics_path}\")\n",
    "\n",
    "    hist_path = os.path.join(args.save_dir, \"history.json\")\n",
    "    with open(hist_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(history, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved training history to: {hist_path}\")\n",
    "\n",
    "    # 8) Grad-CAM ×œ×›××” ×“×•×’×××•×ª ××›×œ ××—×œ×§×”\n",
    "    gradcam_dir = os.path.join(args.save_dir, \"gradcam\")\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "\n",
    "    per_class = args.gradcam_per_class\n",
    "    selected = {i: [] for i in range(NUM_CLASSES)}\n",
    "    # × ×‘×—×¨ ××ª×•×š ×¡×˜ ×”×‘×“×™×§×”\n",
    "    for path, lbl in zip(X_test, y_test):\n",
    "        if len(selected[lbl]) < per_class:\n",
    "            selected[lbl].append(path)\n",
    "        if all(len(selected[i]) >= per_class for i in range(NUM_CLASSES)):\n",
    "            break\n",
    "\n",
    "    print(\"\\nCreating Grad-CAM overlays...\")\n",
    "    model.eval()\n",
    "    for cls_idx, paths in selected.items():\n",
    "        for pth in paths:\n",
    "            # × ×›×™×Ÿ ×˜× ×–×•×¨ ×™×—×™×“\n",
    "            img = cv2.imread(pth, cv2.IMREAD_COLOR)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            img_f = img.astype(np.float32) / 255.0\n",
    "            img_f = (img_f - IMAGENET_MEAN) / IMAGENET_STD\n",
    "            img_f = np.transpose(img_f, (2, 0, 1))  # CHW\n",
    "\n",
    "            img_tensor = torch.from_numpy(img_f.astype(np.float32)).unsqueeze(0)\n",
    "\n",
    "            cam = gradcam_resnet50(model, img_tensor, target_class=cls_idx, device=device)\n",
    "            base = Path(pth).stem\n",
    "            out_path = os.path.join(gradcam_dir, f\"class{cls_idx}_{base}.png\")\n",
    "            save_gradcam_overlay(pth, cam, out_path, img_size=IMG_SIZE)\n",
    "            print(\"  Saved:\", out_path)\n",
    "\n",
    "    # 9) ×©××™×¨×ª ××™×“×¢ ×—×œ×•×§×” ×œ×©×—×–×•×¨\n",
    "    split_info = {\n",
    "        \"class_names\": CLASS_NAMES,\n",
    "        \"train_files\": X_train.tolist(),\n",
    "        \"val_files\": X_val.tolist(),\n",
    "        \"test_files\": X_test.tolist(),\n",
    "        \"arch\": args.arch,\n",
    "        \"img_size\": IMG_SIZE,\n",
    "        \"batch\": args.batch,\n",
    "        \"epochs\": args.epochs,\n",
    "        \"seed\": args.seed,\n",
    "    }\n",
    "    split_path = os.path.join(args.save_dir, \"split_config.json\")\n",
    "    with open(split_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(split_info, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nSaved split config to: {split_path}\")\n",
    "\n",
    "    print(\"\\nAll done.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fcebe-a687-463d-83ef-25bd70a7eb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
