{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecf1eb0-0148-4505-9295-01ce8601e738",
   "metadata": {},
   "source": [
    "# Green Sense Project - Syntethic Data Generaiton (FIBO Model by Bria.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ebba98-ad16-4ef0-8608-1466aeba1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompts \n",
    "Prompt_Dried = (\n",
    "    \"Position the camera approximately 30â€“40 meters (about 130 feet) above ground level, \"\n",
    "    \"mounted high on a streetlight or utility pole, \"\n",
    "    \"at a downward diagonal angle typical of fixed municipal surveillance cameras. \"\n",
    "    \"The camera must remain physically distant from the scene, \"\n",
    "    \"with no foreground elements appearing close to the lens. \"\n",
    "    \"Use a wide field of view that captures a broad section of the environment from this elevated position, \"\n",
    "    \"ensuring the scene reads as observed from above rather than eye-level or handheld. \"\n",
    "    \"The framing should never feel intimate or close-up. \"\n",
    "\n",
    "    \"Analyze and replicate the photographic characteristics of the reference images, including lighting quality, \"\n",
    "    \"texture detail level, color palette, and overall aesthetic. \"\n",
    "    \"Ensure ground and pavement surfaces exhibit high texture clarity, with visible materials, patterns, cracks, \"\n",
    "    \"and natural wear consistent with the reference detail level. \"\n",
    "\n",
    "    \"Maintain restrained, muted color tones with noticeable dryness and reduced saturation, \"\n",
    "    \"favoring pale browns, faded yellows, dusty grays, and sun-bleached surfaces. \"\n",
    "    \"Avoid any signs of moisture, freshness, or lush vegetation. \"\n",
    "    \"All surfaces should appear dry, brittle, or weathered by prolonged lack of water, \"\n",
    "    \"while preserving a realistic, documentary-style color balance. \"\n",
    "\n",
    "    \"Generate each image in a completely different environment, rotating between urban streets, city parks, \"\n",
    "    \"public plazas, and residential neighborhoods. Do not replicate any specific locations from the reference images. \"\n",
    "\n",
    "    \"Feature ground surfaces and vegetation that show clear visual indicators of dryness and dehydration, \"\n",
    "    \"including cracked soil, hardened dirt, dust accumulation, dry patches of earth, \"\n",
    "    \"faded or yellowed grass, brittle plants, sparse or thinning vegetation, \"\n",
    "    \"and uneven coloration caused by prolonged exposure to sun and lack of water. \"\n",
    "\n",
    "    \"These visual characteristics should be clearly observable from the elevated viewpoint and occupy a meaningful \"\n",
    "    \"portion of the frame, allowing the scene to be visually interpreted as environmentally dried rather than contaminated. \"\n",
    "\n",
    "    \"Create cohesive, realistic urban scenes where dryness is consistently present across the ground, \"\n",
    "    \"vegetation, and surrounding urban elements, making the dried condition of the environment immediately recognizable, \"\n",
    "    \"while preserving the same compositional structure, scale, and visual language as the contaminated reference images.\"\n",
    ")\n",
    "\n",
    "#healthy\n",
    "Prompt_Health = (\n",
    "    \"Position the camera approximately 30â€“40 meters (about 130 feet) above ground level, \"\n",
    "    \"mounted high on a streetlight or utility pole, \"\n",
    "    \"at a downward diagonal angle typical of fixed municipal surveillance cameras. \"\n",
    "    \"The camera must remain physically distant from the scene, \"\n",
    "    \"with no foreground elements appearing close to the lens. \"\n",
    "    \"Use a wide field of view that captures a broad section of the environment from this elevated position, \"\n",
    "    \"ensuring the scene reads as observed from above rather than eye-level or handheld. \"\n",
    "    \"The framing should never feel intimate or close-up. \"\n",
    "\n",
    "    \"Analyze and replicate the photographic characteristics of the reference images, including lighting quality, \"\n",
    "    \"texture detail level, color palette, and overall aesthetic. \"\n",
    "    \"Ensure ground and pavement surfaces exhibit high texture clarity, with visible materials, patterns, cracks, \"\n",
    "    \"and natural wear consistent with the reference detail level. \"\n",
    "\n",
    "    \"Maintain balanced, natural color tones with healthy saturation, \"\n",
    "    \"featuring realistic greens, warm earth tones, and clean but not artificial-looking surfaces. \"\n",
    "    \"Avoid oversaturated colors, overly polished appearances, or stock-photo aesthetics. \"\n",
    "    \"Preserve a realistic, documentary-style color balance that reflects well-maintained urban environments. \"\n",
    "\n",
    "    \"Generate each image in a completely different environment, rotating between urban streets, city parks, \"\n",
    "    \"public plazas, and residential neighborhoods. Do not replicate any specific locations from the reference images. \"\n",
    "\n",
    "    \"Feature ground surfaces and vegetation that show clear visual indicators of healthy environmental conditions, \"\n",
    "    \"including evenly colored soil, intact ground surfaces, \"\n",
    "    \"lush but realistic grass coverage, full and properly maintained plants, \"\n",
    "    \"consistent vegetation density, and signs of regular care such as trimmed greenery and stable growth patterns. \"\n",
    "\n",
    "    \"These visual characteristics should be clearly observable from the elevated viewpoint and occupy a meaningful \"\n",
    "    \"portion of the frame, allowing the scene to be visually interpreted as environmentally healthy. \"\n",
    "\n",
    "    \"Create cohesive, realistic urban scenes where healthy conditions are consistently present across the ground, \"\n",
    "    \"vegetation, and surrounding urban elements, making the well-maintained and healthy state of the environment \"\n",
    "    \"immediately recognizable, while preserving the same compositional structure, scale, and visual language as the \"\n",
    "    \"contaminated and dried reference images.\"\n",
    ")\n",
    "\n",
    "\n",
    "#cont\n",
    "Prompt_Cont = (\n",
    "\"Position the camera approximately 20â€“30 meters (about 100 feet) above ground level, \"\n",
    "\"mounted high on a streetlight or utility pole, \"\n",
    "\"at a downward diagonal angle typical of fixed municipal surveillance cameras. \"\n",
    "\"The camera must remain physically distant from the scene, \"\n",
    "\"with no foreground elements appearing close to the lens. \"\n",
    "\"Use a wide field of view that captures a broad section of the environment from this elevated position, \"\n",
    "\"ensuring the scene reads as observed from above rather than eye-level or handheld. \"\n",
    "\"The framing should never feel intimate or close-up. \"\n",
    "\"Analyze and replicate the photographic characteristics of the reference images, including lighting quality, \"\n",
    "\"texture detail level, color palette, and overall aesthetic. \"\n",
    "\"Ensure ground and pavement surfaces exhibit high texture clarity, with visible materials, patterns, cracks, \"\n",
    "\"and natural wear consistent with the reference detail level. \"\n",
    "\"Maintain restrained, muted color tones with slight desaturation, \"\n",
    "\"avoiding vibrant greens, clean surfaces, or visually healthy vegetation, \"\n",
    "\"while preserving a realistic, documentary-style color balance. \"\n",
    "\"Generate each image in a completely different environment, rotating between urban streets, city parks, \"\n",
    "\"public plazas, and residential neighborhoods. Do not replicate any specific locations from the reference images. \"\n",
    "\"Feature ground surfaces and vegetation that show visible signs of neglect, heavy exposure to urban conditions, \"\n",
    "\"and prolonged environmental stress, including dirt accumulation, darkened soil areas, \"\n",
    "\"dust layers, debris, litter, surface stains, uneven ground coloration, \"\n",
    "\"and irregular or damaged plant growth patterns clearly visible within the scene. \"\n",
    "\"These visual characteristics should be clearly observable from the elevated viewpoint and occupy a meaningful \"\n",
    "\"portion of the frame, allowing the scene to be visually interpreted as environmentally degraded. \"\n",
    "\"Create cohesive, realistic urban scenes where these conditions are consistently present across the ground, \"\n",
    "\"vegetation, and surrounding urban elements, making the degraded state of the environment immediately recognizable.\"\n",
    ")\n",
    "\n",
    "\n",
    "Prompt_Cont_Health = (\n",
    "\"Position the camera approximately 40-60 meters (about 150 feet) above ground level, \"\n",
    "\"mounted high on a streetlight or utility pole, \"\n",
    "\"at a downward diagonal angle typical of fixed municipal surveillance cameras. \"\n",
    "\"The camera must remain physically distant from the scene, \"\n",
    "\"with no foreground elements appearing close to the lens. \"\n",
    "\"Use a wide field of view that captures a broad section of the environment from this elevated position, \"\n",
    "\"ensuring the scene reads as observed from above rather than eye-level or handheld. \"\n",
    "\"The framing should never feel intimate or close-up. \"\n",
    "\n",
    "\"Analyze and replicate the photographic characteristics of the reference images, including lighting quality, \"\n",
    "\"texture detail level, color palette, and overall aesthetic. \"\n",
    "\n",
    "\"Ensure ground and pavement surfaces exhibit high texture clarity, with visible materials, patterns, cracks, \"\n",
    "\"and natural wear consistent with the reference detail level. \"\n",
    "\n",
    "\"Maintain restrained, muted overall color tones with slight desaturation, \"\n",
    "\"while explicitly preserving green vegetation that appears biologically healthy and alive. \"\n",
    "\"Vegetation must retain natural green hues and visual vitality, \"\n",
    "\"but should simultaneously appear environmentally contaminated rather than clean or pristine. \"\n",
    "\n",
    "\"Vegetation should show clear signs of urban pollution and environmental contamination, \"\n",
    "\"including dust accumulation, soot, grime, polluted soil, darkened or stained ground around plants, \"\n",
    "\"airborne residue on leaves, and proximity to debris or litter. \"\n",
    "\"The plants should look resilient and surviving despite contamination, \"\n",
    "\"not wilted, dead, or dried out. \"\n",
    "\n",
    "\"Generate each image in a completely different environment, rotating between urban streets, city parks, \"\n",
    "\"public plazas, and residential neighborhoods. Do not replicate any specific locations from the reference images. \"\n",
    "\n",
    "\"Feature ground surfaces and surrounding urban elements that show visible signs of neglect, heavy exposure \"\n",
    "\"to urban conditions, and prolonged environmental stress, including dirt accumulation, surface stains, \"\n",
    "\"uneven coloration, debris, and litter. \"\n",
    "\n",
    "\"These visual characteristics should be clearly observable from the elevated viewpoint and occupy a meaningful \"\n",
    "\"portion of the frame, allowing the scene to be interpreted as environmentally contaminated despite living vegetation. \"\n",
    "\n",
    "\"Create cohesive, realistic urban scenes where environmental contamination is consistently present across \"\n",
    "\"the ground, vegetation, and surrounding urban elements, making the polluted state of the environment \"\n",
    "\"immediately recognizable.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40c69b2-6a81-41f4-9256-f339004774de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Processing #1 â†’ https://i.ibb.co/DP9kkMXw/img-healthy-724.jpg\n",
      "ðŸ“ Saved JSON â†’ /Users/dorhalevy/Downloads/logs/image_001_initial.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ” Saved â†’ /Users/dorhalevy/Downloads/image_001.png\n",
      "\n",
      "ðŸŽ‰ DONE â€” All images processed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ========= CONFIG =========\n",
    "\n",
    "BRIA_TOKEN = \"\"\n",
    "BRIA_BASE_URL = \"https://engine.prod.bria-api.com/v2\"\n",
    "BRIA_GENERATE_URL = f\"{BRIA_BASE_URL}/image/generate\"\n",
    "\n",
    "OUTPUT_FOLDER = Path(\"\")\n",
    "LOG_FOLDER = OUTPUT_FOLDER / \"logs\"\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "LOG_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_CONCURRENT = 2\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n",
    "\n",
    "# ========= IMAGE LIST =========\n",
    "# Inspirations Images\n",
    "IMAGE_URLS = [\n",
    "    \"https://i.ibb.co/DP9kkMXw/img-healthy-724.jpg\"\n",
    "]\n",
    "\n",
    "PROMPT_TEXT = Prompt_Health\n",
    "\n",
    "# ========= HELPERS =========\n",
    "\n",
    "async def save_json(path: Path, payload, response):\n",
    "    path.write_text(json.dumps({\"payload\": payload, \"response\": response}, indent=4))\n",
    "    print(f\"ðŸ“ Saved JSON â†’ {path}\")\n",
    "\n",
    "async def download_image(session, url: str, out_path: Path):\n",
    "    async with session.get(url) as resp:\n",
    "        content = await resp.read()\n",
    "    out_path.write_bytes(content)\n",
    "    print(f\"   âœ” Saved â†’ {out_path}\")\n",
    "\n",
    "async def poll_status(session, status_url: str, base_name: str):\n",
    "    headers = {\"api_token\": BRIA_TOKEN}\n",
    "    log_file = LOG_FOLDER / f\"{base_name}_status.json\"\n",
    "\n",
    "    while True:\n",
    "        await asyncio.sleep(2)\n",
    "        async with session.get(status_url, headers=headers) as resp:\n",
    "            try:\n",
    "                res = await resp.json()\n",
    "            except aiohttp.ContentTypeError:\n",
    "                print(f\"âŒ [{base_name}] HTML status response â€” skipping poll\")\n",
    "                return None\n",
    "\n",
    "        log_file.write_text(json.dumps(res, indent=4))\n",
    "        status = res.get(\"status\")\n",
    "\n",
    "        if status == \"IN_PROGRESS\":\n",
    "            return None\n",
    "        if status == \"COMPLETED\":\n",
    "            return res.get(\"result\", {}).get(\"image_url\")\n",
    "\n",
    "        print(f\"âŒ [{base_name}] Status Error:\", res)\n",
    "        return None\n",
    "\n",
    "async def process_single_image(session, image_url: str, index: int, progress):\n",
    "    async with semaphore:\n",
    "        base_name = f\"image_{index:03d}\"\n",
    "        print(f\"\\nðŸ”¹ Processing #{index} â†’ {image_url}\")\n",
    "\n",
    "        payload = {\"prompt\": PROMPT_TEXT, \"images\": [image_url]}\n",
    "        headers = {\"api_token\": BRIA_TOKEN, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "        async with session.post(BRIA_GENERATE_URL, json=payload, headers=headers) as resp:\n",
    "            try:\n",
    "                initial = await resp.json()\n",
    "            except aiohttp.ContentTypeError:\n",
    "                print(f\"âŒ [{base_name}] HTML response instead of JSON â€” skipping\")\n",
    "                progress.update(1)\n",
    "                return\n",
    "\n",
    "        await save_json(LOG_FOLDER / f\"{base_name}_initial.json\", payload, initial)\n",
    "\n",
    "        if resp.status == 200 and \"result\" in initial:\n",
    "            url = initial[\"result\"].get(\"image_url\")\n",
    "            if url:\n",
    "                out_path = OUTPUT_FOLDER / f\"{base_name}.png\"\n",
    "                await download_image(session, url, out_path)\n",
    "                progress.update(1)\n",
    "                return\n",
    "\n",
    "        if resp.status == 202 and \"status_url\" in initial:\n",
    "            status_url = initial[\"status_url\"]\n",
    "            while True:\n",
    "                out_url = await poll_status(session, status_url, base_name)\n",
    "                if out_url:\n",
    "                    out_path = OUTPUT_FOLDER / f\"{base_name}.png\"\n",
    "                    await download_image(session, out_url, out_path)\n",
    "                    progress.update(1)\n",
    "                    return\n",
    "\n",
    "        print(f\"âŒ [{base_name}] Error Response:\", initial)\n",
    "        progress.update(1)\n",
    "\n",
    "# ========= MAIN =========\n",
    "\n",
    "async def main():\n",
    "    connector = aiohttp.TCPConnector(limit=20)\n",
    "    timeout = aiohttp.ClientTimeout(total=None)\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "        with tqdm(total=len(IMAGE_URLS), desc=\"Processing Images\") as progress:\n",
    "            tasks = [process_single_image(session, url, i, progress) for i, url in enumerate(IMAGE_URLS, start=1)]\n",
    "            await asyncio.gather(*tasks)\n",
    "\n",
    "    print(\"\\nðŸŽ‰ DONE â€” All images processed!\")\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    await main()\n",
    "else:\n",
    "    loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfb236-bb97-4167-82a0-d45a750fd0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
