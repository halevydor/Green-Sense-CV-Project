# ğŸŒ³ VLM Sense â€” Greenspace Quality Classifier

A Computer Vision pipeline that classifies park and greenspace images into **Healthy**, **Dried**, or **Contaminated** categories using multi-model feature fusion (CLIP + DINOv2) and an ensemble prediction strategy.

---

## ğŸ“ Project Structure

```
vlm_sense/
â”œâ”€â”€ app.py                   # Streamlit web interface (single image + batch evaluation)
â”œâ”€â”€ config.py                # Central configuration (prompts, model names, paths)
â”œâ”€â”€ train.py                 # Training pipeline (feature extraction + Random Forest)
â”œâ”€â”€ dataset.py               # Dataset loading and CLIP preprocessing
â”œâ”€â”€ scene_features.py        # CLIP + DINOv2 scene-level feature extraction
â”œâ”€â”€ dino_features.py         # DINOv2 model wrapper and embedding extraction
â”œâ”€â”€ vegetation_detector.py   # HSV color-based vegetation detection + road sign masking
â”œâ”€â”€ vegetation_features.py   # Vegetation crop embeddings + color/texture analysis
â”œâ”€â”€ models/                  # Trained model artifacts
â”‚   â”œâ”€â”€ best_classifier_dino.pkl   # Random Forest (CLIP+DINO features, 1795-dim)
â”‚   â”œâ”€â”€ scaler_dino.pkl            # StandardScaler for feature normalization
â”‚   â”œâ”€â”€ best_classifier.pkl        # Fallback RF (CLIP-only, 1027-dim)
â”‚   â”œâ”€â”€ scaler.pkl                 # Fallback scaler
â”‚   â”œâ”€â”€ confusion_matrix.png       # Evaluation confusion matrix
â”‚   â”œâ”€â”€ feature_importance.png     # Top feature importances
â”‚   â””â”€â”€ metrics.json               # Accuracy, F1, etc.
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ packages.txt             # System dependencies (Streamlit Cloud)
â”œâ”€â”€ Data/                    # Training/validation/test images (not included in deployment)
â””â”€â”€ System_Architecture_Documentation.html
```

---

## ğŸ§  Architecture

### Feature Extraction (1,795-dimensional vector)

| Component | Dimensions | Description |
|---|---|---|
| CLIP Scene Embedding | 512 | Global scene understanding via ViT-B/32 |
| CLIP Vegetation Embedding | 512 | Mean-pooled crops from detected vegetation regions |
| DINOv2 Scene Embedding | 384 | Fine-grained visual texture via ViT-S/14 |
| DINOv2 Vegetation Embedding | 384 | Crop-level texture features |
| Color/Texture Features | 3 | Green ratio, edge density, vegetation coverage |

### Prediction Pipeline (Ensemble Strategy)

1. **Road Sign Masking** â€” HSV-based detection of red/blue/white rectangular objects, inpainted before scene analysis so signs aren't misread as contamination
2. **Random Forest** â€” Trained on 1,795-dim feature vectors
3. **CLIP Prompt Voting** â€” 30 text prompts (10 per class) scored against the image
4. **Ensemble** â€” 60% RF + 40% CLIP, with boosts:
   - Top-1 prompt class: +5%
   - 2/3 top-3 majority: +7%
   - 3/3 top-3 consensus: full override (98% confidence)

### Decision Hierarchy

| Priority | Condition | Action |
|---|---|---|
| 1 | 3/3 top prompts agree | Override â†’ 98% confidence |
| 2 | 2/3 top prompts agree | +7% boost to majority class |
| 3 | RF confidence < 65% | Use ensemble (RF+CLIP) |
| 4 | RF confident â‰¥ 65% | Trust RF alone |

---

## ğŸš€ How to Run Locally

```bash
# Create virtual environment
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
```

The app opens at `http://localhost:8501` with two tabs:

- **Single Image Analysis** â€” Upload one image, see detailed results with confidence breakdown
- **Batch Evaluation** â€” Upload labeled images per class, get accuracy, F1, confusion matrix, ROC curves

---

## â˜ï¸ Deploy to Streamlit Cloud

1. Push this folder to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your repository, select `app.py`
4. Deploy â€” the app auto-downloads CLIP and DINOv2 on first run

---

## ğŸ”§ Key Design Decisions

- **Multi-model fusion** â€” CLIP captures semantic meaning ("healthy park"), DINOv2 captures visual texture (leaf patterns)
- **HSV vegetation detection** â€” Lightweight fallback instead of GroundingDINO for cloud deployment (< 1GB RAM)
- **Road sign masking** â€” Prevents misclassification of urban signage as contamination
- **Ensemble voting** â€” Combines learned features (RF) with zero-shot reasoning (CLIP prompts) for robustness

---

## âš™ï¸ System Requirements

| Environment | RAM | Notes |
|---|---|---|
| Cloud (Streamlit) | 1 GB | Auto-resize, CPU-only, single-threaded |
| Local | 4 GB+ | Faster processing, optional GPU support |
| Python | 3.8+ | Tested on 3.10â€“3.13 |

---

## ğŸ”§ Troubleshooting

| Problem | Solution |
|---|---|
| App won't start | Check Python â‰¥ 3.8, reinstall: `pip install -r requirements.txt --force-reinstall` |
| Out of memory (cloud) | Images are auto-resized to 1024px; reduce `max_size` in `app.py` if needed |
| "Models not found" | Ensure `models/` folder contains `.pkl` files |
| Wrong predictions | Verify the trained model matches the feature dimension (1795 for DINO-enhanced) |

---

**Version:** February 2026  
**Status:** Production-Ready âœ…
